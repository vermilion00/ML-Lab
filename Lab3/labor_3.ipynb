{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung in TensorFlow und Neural Networks\n",
    "\n",
    "<p>In diesem Labor lernen wir die Grundlagen über Neuronale Netze, Neuronen und Layer.</p>\n",
    "<p>Wir werden auch die Grundlagen von TensorFlow erlernen und ein einfaches NN mit TensorFlow bauen.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "<p>Neuronale Netze, auch bekannt als künstliche neuronale Netze (ANN) oder simulierte neuronale Netze (SNN), sind ein Teilbereich des maschinellen Lernens. Ihr Name und ihre Struktur sind vom menschlichen Gehirn inspiriert und ahmen die Art und Weise nach, in der biologische Neuronen einander Signale übermitteln.</p>\n",
    "<p>Neuronale Netze lernen (oder werden trainiert) durch die Verarbeitung von Beispielen, von denen jedes eine bekannte \"Eingabe\" und ein bekanntes \"Ergebnis\" enthält, und bilden wahrscheinlichkeitsgewichtete Assoziationen zwischen den beiden, die in der Datenstruktur des Netzes selbst gespeichert sind.</p>\n",
    "<p>Das Training eines neuronalen Netzes anhand eines bestimmten Beispiels erfolgt in der Regel durch die Bestimmung der Differenz zwischen der verarbeiteten Ausgabe des Netzes (häufig eine Vorhersage) und einer Zielausgabe. Diese Differenz ist der Fehler. Das Netz passt dann seine gewichteten Assoziationen gemäß einer Lernregel und unter Verwendung dieses Fehlerwertes an. </p>\n",
    "\n",
    "-------\n",
    "<p>Neural networks learn (or are trained) by processing examples, each of which contains a known \"input\" and \"result,\" forming probability-weighted associations between the two, which are stored within the data structure of the net itself. The training of a neural network from a given example is usually conducted by determining the difference between the processed output of the network (often a prediction) and a target output. This difference is the error. The network then adjusts its weighted associations according to a learning rule and using this error value. Successive adjustments will cause the neural network to produce output which is increasingly similar to the target output. After a sufficient number of these adjustments the training can be terminated based upon certain criteria</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Solche Systeme \"lernen\", Aufgaben auszuführen, indem sie Beispiele betrachten, im Allgemeinen ohne mit aufgabenspezifischen Regeln programmiert zu sein. Bei der Bilderkennung könnten sie beispielsweise lernen, Bilder mit Katzen zu erkennen, indem sie Beispielbilder analysieren, die manuell als \"Katze\" oder \"keine Katze\" gekennzeichnet wurden, und die Ergebnisse verwenden, um Katzen in anderen Bildern zu erkennen. Sie tun dies ohne jegliches Vorwissen über Katzen, z. B. dass sie Fell, Schwänze, Schnurrhaare und katzenähnliche Gesichter haben. Stattdessen generieren sie automatisch Erkennungsmerkmale aus den verarbeiteten Beispielen.</p>\n",
    "\n",
    "--------\n",
    "<p>Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with task-specific rules. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the results to identify cats in other images. They do this without any prior knowledge of cats, for example, that they have fur, tails, whiskers, and cat-like faces. Instead, they automatically generate identifying characteristics from the examples that they process.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://miro.medium.com/max/1400/0*_SH7tsNDTkGXWtZb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Models\n",
    "<p>Die Verarbeitungseinheiten sind in Layern angeordnet. Ein neuronales Netz besteht in der Regel aus drei Teilen: einer Input-Layer, einer oder mehreren Hidden-Layern und einer Output-Layer mit einer oder mehreren Zielfelder. Die Neurons sind mit unterschiedlichen Verbindungsstärken (oder Gewichten) verbunden. Die Eingabedaten werden der ersten Layer vorgelegt, und die Werte werden von jedem Neuron an jedes Neuron im nächsten Layer weitergegeben. Schließlich wird von der Output-Layer ein Ergebnis geliefert.</p>\n",
    "\n",
    "-----------\n",
    "\n",
    "<p>The processing units are arranged in layers. There are typically three parts in a neural network: an input layer, with units representing the input fields; one or more hidden layers; and an output layer, with a unit or units representing the target field(s). The units are connected with varying connection strengths (or weights). Input data are presented to the first layer, and values are propagated from each neuron to every neuron in the next layer. Eventually, a result is delivered from the output layer.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In neural networks, we send the input to each of the neuron on input layer. (e.g. here each pixel to each neuron), Each neuron on each layer has a predefined weight. Based on this weight and a bias, we calculate the value on neuron, if this is greater than the activation function, we activate the neuron. This happens till the end. At the end, we based on probability function, we decide the output. This is called forward propogation. If the output is wrong (Which in most of the cases is) we change the weights based on errors (This is called backward feeding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we need some parameters to tune in the neural networks. These parametes are called hyperparameters. For us, the important parameters are - Epoch, Learning Rate, Batch Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epoch -** How many time we feed the data to NN\n",
    "<br/>**Batch Size -** Dividing the input data in smaller portions\n",
    "<br/>**Learning Rate -** Gredient on each neuron is after each epoch (loss/weight). Gredient is multiplied by the learning rate (Between 0 to 1), so basically (loss*LR/weight) = y. This y is subtracted from weight to adjust the weight for next round. If we choose a bigger number for learning rate, we will make bigger changes to weight very quickly and there is possibility to miss out the actual correct weight. If we choose too small a number, it will take a long long time to reach the required weight. Thus we need to make sure that we select the correct learning rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](nn.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "<p>Die Open-Source-Kernbibliothek, die Sie beim Entwickeln und Trainieren von ML-Modellen unterstützt.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install TensorFlow\n",
    "<p>pip install tensorflow</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import tensorflow, pandas, and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "# import other libs\n",
    "# import pyplot from matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schreiben Sie eine Funktion build_model / Write a function build_model\n",
    "\n",
    "<p>Diese Funktion benötigt ein Argument - learning_rate / This function takes one argument - learning_rate</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def build_model(learning_rate):\n",
    "    ## add sequential model from keras library into a variable. e.g. model = tf.keras....\n",
    "    ## add one layer of one neuron to this model. e.g model.add(tf.keras.layers.Dense())\n",
    "    ## compile the model using RMSprop compiler, \"mean_squared_error\" loss, and RootMeanSquaredError metrics\n",
    "    ## return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schreiben einer train_model-Funktion / Write a function - train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def train_model(model, feature, label, epochs, batch_size):\n",
    "    ## Feed the feature values and the label values to the model using model.fit method. This will make model learn. e.g history = model.fit(...)\n",
    "    ## Gather the trained model's weight and bias using model.get_weights\n",
    "    ## Store the list of epochs from the trained model separately in a variable called epochs. e.g. epochs = history.epochs\n",
    "    ## Write the history of each epoch using dataFrame. e.g. pd.DataFrame(history.history)\n",
    "    ## get \"root_mean_squared_error\" from the history. e.g. rmse = history[\"root_mean_squared_error\"]\n",
    "    ## return weight, bias, epochs, root mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schreiben Sie eine Funktion plot_model / Write a function plot_model\n",
    "<p>plot_model hat vier Argumente - trained_weight, trained_bias, feature und label / it has four arguments - trained_weights, trained_bias, feature, and label</p>\n",
    "<p>Wir verwenden pyplot, um ein \"scatter plot\" von Features und Labels zu erstellen / We are using pyplot to ploat a scatter plot with features and labels</p>\n",
    "<p>Mit trained_bias und trained_weight zeichnen wir eine Regressionslinie mit der Funktion y = mx+c / With trained_bias and trained_weights we will calculate the regression line</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def plot_model(trained_weight, trained_bias, feature, label):\n",
    "    ## set xLabel as feature and yLabel as label on plot using pyplot\n",
    "    ## plot a scatter plot\n",
    "    ## to plot a line, take x0 = 0, y0 = trained_bias, x1 as the last value of feature and y1 = mx + c\n",
    "    ## where m = trained_weight, x = x1, c = trained_bias\n",
    "    ## plot the line with x0 x1, y0 y1\n",
    "    ## show plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schreiben Sie eine Funktion plot_loss_curve / Write a function plot_loss_curve\n",
    "<p>plot_loss_curve hat zwei Argumente - epochs, und rmse - root mean square error</p>\n",
    "<p>Darstellung von epochs und rmse mit pyplot</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## def plot_loss_curve(epochs, rmse)\n",
    "    ## set xLabel as Epoch and yLabel as \"Root Mean Squared Error\"\n",
    "    ## pyplot.plot(epochs,rmse)\n",
    "    ## show plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testdaten aufnehmen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_feature = ([1.0, 2.0,  3.0,  4.0,  5.0,  6.0,  7.0,  8.0,  9.0, 10.0, 11.0, 12.0])\n",
    "# my_label   = ([5.0, 8.8,  9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2])\n",
    "\n",
    "# declare a new variable learning_rate = 100\n",
    "# declare new variable epochs = 500\n",
    "# declare new variable batch_size = 12\n",
    "# build model by calling build_model function. Use learning_rate as input parameter. Save the return value in a new variable my_model\n",
    "# train model by calling train_model function. Use my_model, my_feature, my_label, epochs, batch_size as input parameters. Save return values (trained_weight, trained_bias, epochs, rmse) in new variables\n",
    "# plot train model using plot_model function. \n",
    "# plot loss curve using plot_loss_curve function.\n",
    "# see the result. Based on result, update learning_rate and epoch, to get correct linear regression line and loss curve approaching zero."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
